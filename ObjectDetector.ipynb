{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "188e57f2-7230-4f28-95fe-9302410e2771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pdb\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72528540-70cc-4b81-aec1-c155b2b5d4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fasterrcnn(file_path = None, num_classes = 91):\n",
    "    model = fasterrcnn_resnet50_fpn(weights='DEFAULT')\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    print(\"Número de características de entrada antes de la modificación:\", in_features)\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    if file_path is not None:\n",
    "        checkpoint = torch.load(file_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d2efbc2-7a88-459a-bd60-e1977e0118f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de características de entrada antes de la modificación: 1024\n",
      "{0: '_', 1: 'keys'}\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "model = get_fasterrcnn(\"model_finetuned_v2.pth\", 92)\n",
    "model.eval()\n",
    "\n",
    "# Load COCO labels\n",
    "# with open('coco_categories.json', 'r') as file:\n",
    "#     categories_data = json.load(file)\n",
    "# categories = categories_data[\"categories\"]\n",
    "\n",
    "# class_dict = {category[\"id\"]: category[\"name\"] for category in categories}\n",
    "# class_dict[91] = \"keys\"\n",
    "class_dict = {0: \"_\", 1: \"keys\"}\n",
    "print(class_dict)\n",
    "print(len(class_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8664ca7-67f6-4c31-ae9e-fe279367b39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6c16443-2690-4e4e-8ec3-65acf4351355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for drawing a bounding box and label on the image\n",
    "def draw_box(image, box, label):\n",
    "    color = (0, 255, 0)  # Green\n",
    "    thickness = 2\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = 0.5\n",
    "    #pdb.set_trace()\n",
    "    text = f\"{class_dict[label]}\"\n",
    "\n",
    "    cv2.rectangle(image, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), color, thickness)\n",
    "    \n",
    "    cv2.putText(image, text, (int(box[0]), int(box[1]) - 5), font, font_scale, color, thickness)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7cae11eb-7c64-4576-b460-5c7d7c0bcd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to limit the number of bounding boxes\n",
    "def intersection_over_union(box_a, box_b):\n",
    "    x1_a, y1_a, x2_a, y2_a = box_a\n",
    "    x1_b, y1_b, x2_b, y2_b = box_b\n",
    "\n",
    "    area_a = (x2_a - x1_a + 1) * (y2_a - y1_a + 1)\n",
    "    area_b = (x2_b - x1_b + 1) * (y2_b - y1_b + 1)\n",
    "\n",
    "    x_intersection = max(0, min(x2_a, x2_b) - max(x1_a, x1_b) + 1)\n",
    "    y_intersection = max(0, min(y2_a, y2_b) - max(y1_a, y1_b) + 1)\n",
    "    intersection = x_intersection * y_intersection\n",
    "\n",
    "    union = area_a + area_b - intersection\n",
    "\n",
    "    iou = intersection / union\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4b21ff6-bce5-4cf8-a64b-df5793a98fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(frame):\n",
    "    # Convert from BGR to RGB\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    input_image = transform(frame)\n",
    "\n",
    "    predictions = model([input_image])\n",
    "    \n",
    "    labels = predictions[0]['labels'].tolist()\n",
    "    boxes = predictions[0]['boxes'].tolist()\n",
    "    scores = predictions[0]['scores'].tolist()\n",
    "\n",
    "    # Filtering detections based on trust\n",
    "    filtered_boxes = []\n",
    "    filtered_labels = []\n",
    "    for box, label, score in zip(boxes, labels, scores):\n",
    "        if score > 0.5:  # Threshold\n",
    "            filtered_boxes.append(box)\n",
    "            filtered_labels.append(label)\n",
    "\n",
    "    # Remove overlapping bounding boxes\n",
    "    non_overlapping_boxes = []\n",
    "    non_overlapping_labels = []\n",
    "    for i, box in enumerate(filtered_boxes):\n",
    "        overlapping = False\n",
    "        for j, other_box in enumerate(filtered_boxes):\n",
    "            if i != j and intersection_over_union(box, other_box) > 0.5:\n",
    "                overlapping = True\n",
    "                break\n",
    "        if not overlapping:\n",
    "            non_overlapping_boxes.append(box)\n",
    "            non_overlapping_labels.append(filtered_labels[i])\n",
    "\n",
    "    # Draw bounding boxes and labels on the image\n",
    "    for box, label in zip(non_overlapping_boxes, non_overlapping_labels):\n",
    "        frame = draw_box(frame, box, label)\n",
    "\n",
    "    # Convert back from RGB to BGR\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45da7576-fabd-4433-ba25-9e46dca88d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(video_path, output_path):\n",
    "    video_capture = cv2.VideoCapture(video_path)\n",
    "\n",
    "    fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
    "    frame_count = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    video_writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "    frame_number = 0\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        processed_frame = process_frame(frame)\n",
    "        video_writer.write(processed_frame)\n",
    "        \n",
    "        frame_number += 1\n",
    "        progress = (frame_number / frame_count) * 100\n",
    "        print(f\"Processing... {progress:.2f}% completed\", end='\\r')\n",
    "\n",
    "    video_capture.release()\n",
    "    video_writer.release()\n",
    "    print(\"\\nProcess completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0184d90-a009-4df6-a1da-1d3892981f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing... 100.00% completed\n",
      "Process completed\n"
     ]
    }
   ],
   "source": [
    "input_video_path = \"input_video2.mp4\"\n",
    "output_video_path = \"output_video5.mp4\"\n",
    "\n",
    "process_video(input_video_path, output_video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae54b05-0f3c-45d1-a05a-8866d8a35162",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
