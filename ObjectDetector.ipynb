{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f344d3e7-e03b-4850-8970-d8f4316bad68",
   "metadata": {},
   "source": [
    "# Method that processes a video and detects objects with Faster CRNN based on COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "188e57f2-7230-4f28-95fe-9302410e2771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pdb\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81544cc-8ded-425f-82db-90bbfa4048a8",
   "metadata": {},
   "source": [
    "### If there is a path_file, load the desired model, and if not, return the original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72528540-70cc-4b81-aec1-c155b2b5d4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fasterrcnn(file_path = None, num_classes = 91):\n",
    "    model = fasterrcnn_resnet50_fpn(weights='DEFAULT')\n",
    "    if file_path is not None:\n",
    "        checkpoint = torch.load(file_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d2efbc2-7a88-459a-bd60-e1977e0118f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '__background__', 1: 'person', 2: 'bicycle', 3: 'car', 4: 'motorcycle', 5: 'airplane', 6: 'bus', 7: 'train', 8: 'truck', 9: 'boat', 10: 'traffic light', 11: 'fire hydrant', 13: 'stop sign', 14: 'parking meter', 15: 'bench', 16: 'bird', 17: 'cat', 18: 'dog', 19: 'horse', 20: 'sheep', 21: 'cow', 22: 'elephant', 23: 'bear', 24: 'zebra', 25: 'giraffe', 27: 'backpack', 28: 'umbrella', 31: 'handbag', 32: 'tie', 33: 'suitcase', 34: 'frisbee', 35: 'skis', 36: 'snowboard', 37: 'sports ball', 38: 'kite', 39: 'baseball bat', 40: 'baseball glove', 41: 'skateboard', 42: 'surfboard', 43: 'tennis racket', 44: 'bottle', 46: 'wine glass', 47: 'cup', 48: 'fork', 49: 'knife', 50: 'spoon', 51: 'bowl', 52: 'banana', 53: 'apple', 54: 'sandwich', 55: 'orange', 56: 'broccoli', 57: 'carrot', 58: 'hot dog', 59: 'pizza', 60: 'donut', 61: 'cake', 62: 'chair', 63: 'couch', 64: 'potted plant', 65: 'bed', 67: 'dining table', 70: 'toilet', 72: 'tv', 73: 'laptop', 74: 'mouse', 75: 'remote', 76: 'keyboard', 77: 'cell phone', 78: 'microwave', 79: 'oven', 80: 'toaster', 81: 'sink', 82: 'refrigerator', 84: 'book', 85: 'clock', 86: 'vase', 87: 'scissors', 88: 'teddy bear', 89: 'hair drier', 90: 'toothbrush', 91: 'keys'}\n",
      "82\n"
     ]
    }
   ],
   "source": [
    "model = get_fasterrcnn(num_classes = 92)\n",
    "model.eval()\n",
    "\n",
    "# Load COCO labels\n",
    "with open('annotations/coco_categories.json', 'r') as file:\n",
    "    categories_data = json.load(file)\n",
    "categories = categories_data[\"categories\"]\n",
    "\n",
    "class_dict = {category[\"id\"]: category[\"name\"] for category in categories}\n",
    "class_dict[91] = \"keys\"\n",
    "#class_dict = {0: \"_\", 1: \"keys\"}\n",
    "print(class_dict)\n",
    "print(len(class_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8664ca7-67f6-4c31-ae9e-fe279367b39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a446a5b3-9bdf-4c9d-979d-3b35c6170442",
   "metadata": {},
   "source": [
    "### Function for drawing a bounding box and label on the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6c16443-2690-4e4e-8ec3-65acf4351355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_box(image, box, label):\n",
    "    color = (0, 255, 0)  # Green\n",
    "    thickness = 2\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = 0.5\n",
    "    #pdb.set_trace()\n",
    "    text = f\"{class_dict[label]}\"\n",
    "\n",
    "    cv2.rectangle(image, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), color, thickness)\n",
    "    \n",
    "    cv2.putText(image, text, (int(box[0]), int(box[1]) - 5), font, font_scale, color, thickness)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca192696-54e9-4c4e-a622-87ae9f6cbe7a",
   "metadata": {},
   "source": [
    "### Function to limit the number of bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7cae11eb-7c64-4576-b460-5c7d7c0bcd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_over_union(box_a, box_b):\n",
    "    x1_a, y1_a, x2_a, y2_a = box_a\n",
    "    x1_b, y1_b, x2_b, y2_b = box_b\n",
    "\n",
    "    area_a = (x2_a - x1_a + 1) * (y2_a - y1_a + 1)\n",
    "    area_b = (x2_b - x1_b + 1) * (y2_b - y1_b + 1)\n",
    "\n",
    "    x_intersection = max(0, min(x2_a, x2_b) - max(x1_a, x1_b) + 1)\n",
    "    y_intersection = max(0, min(y2_a, y2_b) - max(y1_a, y1_b) + 1)\n",
    "    intersection = x_intersection * y_intersection\n",
    "\n",
    "    union = area_a + area_b - intersection\n",
    "\n",
    "    iou = intersection / union\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e03ebdf-8db5-4cbd-891b-13b6b02b8d78",
   "metadata": {},
   "source": [
    "### Function to process 1 frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4b21ff6-bce5-4cf8-a64b-df5793a98fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(frame):\n",
    "    # Convert from BGR to RGB\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    input_image = transform(frame)\n",
    "\n",
    "    predictions = model([input_image])\n",
    "    \n",
    "    labels = predictions[0]['labels'].tolist()\n",
    "    boxes = predictions[0]['boxes'].tolist()\n",
    "    scores = predictions[0]['scores'].tolist()\n",
    "\n",
    "    # Filtering detections based on trust\n",
    "    filtered_boxes = []\n",
    "    filtered_labels = []\n",
    "    for box, label, score in zip(boxes, labels, scores):\n",
    "        if score > 0.5:  # Threshold\n",
    "            filtered_boxes.append(box)\n",
    "            filtered_labels.append(label)\n",
    "\n",
    "    # Remove overlapping bounding boxes\n",
    "    non_overlapping_boxes = []\n",
    "    non_overlapping_labels = []\n",
    "    for i, box in enumerate(filtered_boxes):\n",
    "        overlapping = False\n",
    "        for j, other_box in enumerate(filtered_boxes):\n",
    "            if i != j and intersection_over_union(box, other_box) > 0.5:\n",
    "                overlapping = True\n",
    "                break\n",
    "        if not overlapping:\n",
    "            non_overlapping_boxes.append(box)\n",
    "            non_overlapping_labels.append(filtered_labels[i])\n",
    "\n",
    "    # Draw bounding boxes and labels on the image\n",
    "    for box, label in zip(non_overlapping_boxes, non_overlapping_labels):\n",
    "        frame = draw_box(frame, box, label)\n",
    "\n",
    "    # Convert back from RGB to BGR\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48fcc9c-54ae-442a-87c5-60cfeb47ba4d",
   "metadata": {},
   "source": [
    "### Function to process the video, using all the functions above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45da7576-fabd-4433-ba25-9e46dca88d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(video_path, output_path):\n",
    "    video_capture = cv2.VideoCapture(video_path)\n",
    "\n",
    "    fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
    "    frame_count = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    video_writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "    frame_number = 0\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        processed_frame = process_frame(frame)\n",
    "        video_writer.write(processed_frame)\n",
    "        \n",
    "        frame_number += 1\n",
    "        progress = (frame_number / frame_count) * 100\n",
    "        print(f\"Processing... {progress:.2f}% completed\", end='\\r')\n",
    "\n",
    "    video_capture.release()\n",
    "    video_writer.release()\n",
    "    print(\"\\nProcess completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0184d90-a009-4df6-a1da-1d3892981f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing... 100.00% completed\n",
      "Process completed\n"
     ]
    }
   ],
   "source": [
    "input_video_path = \"input_video2.mp4\"\n",
    "output_video_path = \"output_video5.mp4\"\n",
    "\n",
    "process_video(input_video_path, output_video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae54b05-0f3c-45d1-a05a-8866d8a35162",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
