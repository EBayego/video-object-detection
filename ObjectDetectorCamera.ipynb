{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b78991a9-c8d7-4153-a41d-e7211be9f037",
   "metadata": {},
   "source": [
    "# Method to implement the object detector to an android application with the camera in real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "188e57f2-7230-4f28-95fe-9302410e2771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pdb\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn, fasterrcnn_resnet50_fpn_v2\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72528540-70cc-4b81-aec1-c155b2b5d4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fasterrcnn(file_path = None, num_classes = None):\n",
    "    model = fasterrcnn_resnet50_fpn_v2(weights='DEFAULT')\n",
    "    if num_classes is None:\n",
    "        return model\n",
    "        \n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    if file_path is not None:\n",
    "        checkpoint = torch.load(file_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d2efbc2-7a88-459a-bd60-e1977e0118f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '__background__', 1: 'person', 2: 'bicycle', 3: 'car', 4: 'motorcycle', 5: 'airplane', 6: 'bus', 7: 'train', 8: 'truck', 9: 'boat', 10: 'traffic light', 11: 'fire hydrant', 13: 'stop sign', 14: 'parking meter', 15: 'bench', 16: 'bird', 17: 'cat', 18: 'dog', 19: 'horse', 20: 'sheep', 21: 'cow', 22: 'elephant', 23: 'bear', 24: 'zebra', 25: 'giraffe', 27: 'backpack', 28: 'umbrella', 31: 'handbag', 32: 'tie', 33: 'suitcase', 34: 'frisbee', 35: 'skis', 36: 'snowboard', 37: 'sports ball', 38: 'kite', 39: 'baseball bat', 40: 'baseball glove', 41: 'skateboard', 42: 'surfboard', 43: 'tennis racket', 44: 'bottle', 46: 'wine glass', 47: 'cup', 48: 'fork', 49: 'knife', 50: 'spoon', 51: 'bowl', 52: 'banana', 53: 'apple', 54: 'sandwich', 55: 'orange', 56: 'broccoli', 57: 'carrot', 58: 'hot dog', 59: 'pizza', 60: 'donut', 61: 'cake', 62: 'chair', 63: 'couch', 64: 'potted plant', 65: 'bed', 67: 'dining table', 70: 'toilet', 72: 'tv', 73: 'laptop', 74: 'mouse', 75: 'remote', 76: 'keyboard', 77: 'cell phone', 78: 'microwave', 79: 'oven', 80: 'toaster', 81: 'sink', 82: 'refrigerator', 84: 'book', 85: 'clock', 86: 'vase', 87: 'scissors', 88: 'teddy bear', 89: 'hair drier', 90: 'toothbrush'}\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "model = get_fasterrcnn()\n",
    "model.eval()\n",
    "\n",
    "# Load COCO labels\n",
    "with open('annotations/coco_categories.json', 'r') as file:\n",
    "    categories_data = json.load(file)\n",
    "categories = categories_data[\"categories\"]\n",
    "\n",
    "class_dict = {category[\"id\"]: category[\"name\"] for category in categories}\n",
    "print(class_dict)\n",
    "print(len(class_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8664ca7-67f6-4c31-ae9e-fe279367b39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6c16443-2690-4e4e-8ec3-65acf4351355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for drawing a bounding box and label on the image\n",
    "def draw_box(image, box, label):\n",
    "    color = (0, 255, 0)  # Green\n",
    "    thickness = 2\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = 0.5\n",
    "    #pdb.set_trace()\n",
    "    text = f\"{class_dict[label]}\"\n",
    "\n",
    "    cv2.rectangle(image, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), color, thickness)\n",
    "    \n",
    "    cv2.putText(image, text, (int(box[0]), int(box[1]) - 5), font, font_scale, color, thickness)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cae11eb-7c64-4576-b460-5c7d7c0bcd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to limit the number of bounding boxes\n",
    "def intersection_over_union(box_a, box_b):\n",
    "    x1_a, y1_a, x2_a, y2_a = box_a\n",
    "    x1_b, y1_b, x2_b, y2_b = box_b\n",
    "\n",
    "    area_a = (x2_a - x1_a + 1) * (y2_a - y1_a + 1)\n",
    "    area_b = (x2_b - x1_b + 1) * (y2_b - y1_b + 1)\n",
    "\n",
    "    x_intersection = max(0, min(x2_a, x2_b) - max(x1_a, x1_b) + 1)\n",
    "    y_intersection = max(0, min(y2_a, y2_b) - max(y1_a, y1_b) + 1)\n",
    "    intersection = x_intersection * y_intersection\n",
    "\n",
    "    union = area_a + area_b - intersection\n",
    "\n",
    "    iou = intersection / union\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4b21ff6-bce5-4cf8-a64b-df5793a98fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(frame):\n",
    "    # Convert from BGR to RGB\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    input_image = transform(frame)\n",
    "\n",
    "    predictions = model([input_image])\n",
    "    \n",
    "    labels = predictions[0]['labels'].tolist()\n",
    "    boxes = predictions[0]['boxes'].tolist()\n",
    "    scores = predictions[0]['scores'].tolist()\n",
    "\n",
    "    # Filtering detections based on trust\n",
    "    filtered_boxes = []\n",
    "    filtered_labels = []\n",
    "    for box, label, score in zip(boxes, labels, scores):\n",
    "        if score > 0.5:  # Threshold\n",
    "            filtered_boxes.append(box)\n",
    "            filtered_labels.append(label)\n",
    "\n",
    "    # Remove overlapping bounding boxes\n",
    "    non_overlapping_boxes = []\n",
    "    non_overlapping_labels = []\n",
    "    for i, box in enumerate(filtered_boxes):\n",
    "        overlapping = False\n",
    "        for j, other_box in enumerate(filtered_boxes):\n",
    "            if i != j and intersection_over_union(box, other_box) > 0.5:\n",
    "                overlapping = True\n",
    "                break\n",
    "        if not overlapping:\n",
    "            non_overlapping_boxes.append(box)\n",
    "            non_overlapping_labels.append(filtered_labels[i])\n",
    "\n",
    "    # Draw bounding boxes and labels on the image\n",
    "    for box, label in zip(non_overlapping_boxes, non_overlapping_labels):\n",
    "        frame = draw_box(frame, box, label)\n",
    "\n",
    "    # Convert back from RGB to BGR\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63dac588-f619-4753-988b-1e6f219ad517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video_from_camera():\n",
    "    video_capture = cv2.VideoCapture(0)  # 0 is usually the default camera\n",
    "\n",
    "    prev_time = time.time()\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        processed_frame = process_frame(frame)\n",
    "\n",
    "        curr_time = time.time()\n",
    "        fps = 1 / (curr_time - prev_time)\n",
    "        prev_time = curr_time\n",
    "        cv2.putText(processed_frame, f\"FPS: {fps:.2f}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "        \n",
    "        cv2.imshow('Video', processed_frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ae54b05-0f3c-45d1-a05a-8866d8a35162",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_video_from_camera()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0103cb-7512-4565-9bba-9d628a31dfab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
